model_type: "SelfAttentionMLP"
n_in: 1024
n_out: 1
n_hidden: [512,256,128]
num_heads: 8
dropout: 0.1